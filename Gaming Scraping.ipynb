{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping prototype\n",
    "\n",
    "The following code is a prototype that scrapes data from Casino City's Gaming Directory. Their current directory informs us on the re-opening of gaming properties in the United States following the Covid-19 pandemic.\n",
    "\n",
    "https://www.gamingdirectory.com/covid-19/reopened/\n",
    "\n",
    "Notes:\n",
    "The site requires registration in order to see an entire directory listing. Otherwise, you are limited to the first 20 records or so. Since the data sits behind a login, scraping cannot be done on the entire dataset. To circumvent this, you must register, login, and save the page locally, and run the code on the local file.\n",
    "\n",
    "The scraping was challenging because of the poor structure of the data. Specifically, the `<div>` tags did not have unique identifiers, making it difficult to differentiate one field from the other. \n",
    "\n",
    "Reference: https://www.dataquest.io/blog/web-scraping-tutorial-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# grab the html file on your local drive\n",
    "url = \"Gaming 2020-06-24.html\"\n",
    "\n",
    "# soupify it\n",
    "soup = BeautifulSoup(open(url),'html.parser')\n",
    "\n",
    "# If you were to grab data from the live site, this is the syntax, but you will only get the first 20 records\n",
    "# page = requests.get(\"https://www.gamingdirectory.com/covid-19/reopened/\")\n",
    "# soup = BeautifulSoup(page.content,'html.parser')\n",
    "\n",
    "# split the data by the div that separates each row\n",
    "split_data = soup.prettify().split('<div style=\"clear:both\">')\n",
    "\n",
    "# here are the relevant column headers\n",
    "DateReopened = []\n",
    "Property = []\n",
    "Jurisdiction = []\n",
    "PropertyType = []\n",
    "DateClosed = []\n",
    "Status = []\n",
    "Article = []\n",
    "ArticleLink = []\n",
    "\n",
    "# loop through the results\n",
    "counter = 0\n",
    "for row in split_data:\n",
    "    if counter > 1 and counter < len(split_data)-1:\n",
    "        soupedrow = BeautifulSoup(row,'html.parser')\n",
    "        DateReopened.append(soupedrow.find_all('div',class_='dateCol data')[0].text)\n",
    "        DateClosed.append(soupedrow.find_all('div',class_='dateCol data')[1].text)\n",
    "        Property.append(soupedrow.find_all('div',class_='orgCol data')[0].text)\n",
    "        PropertyType.append(soupedrow.find_all('div',class_='statusCol data')[0].text)\n",
    "        Status.append(soupedrow.find_all('div',class_='statusCol data')[1].text)\n",
    "        Jurisdiction.append(soupedrow.find_all('div',class_='stateCol data')[0].text)\n",
    "        Article.append(soupedrow.find_all('div',class_='articleCol data')[0].text)\n",
    "    counter = counter + 1\n",
    "    \n",
    "# get rid of \\n (new lines)\n",
    "DateReopened = [item.strip() for item in DateReopened]\n",
    "DateClosed = [item.strip() for item in DateClosed]\n",
    "Property = [item.strip() for item in Property]\n",
    "PropertyType = [item.strip() for item in PropertyType]\n",
    "Status = [item.strip() for item in Status]\n",
    "Jurisdiction = [item.strip() for item in Jurisdiction]\n",
    "Article = [item.strip() for item in Article]\n",
    "\n",
    "GamingExport = pd.DataFrame({\n",
    "    \"DateReopened\": DateReopened,\n",
    "    \"DateClosed\": DateClosed,\n",
    "    \"Property\": Property,\n",
    "    \"PropertyType\": PropertyType,\n",
    "    \"Status\": Status,\n",
    "    \"Jurisdiction\": Jurisdiction,\n",
    "    \"Article\": Article\n",
    "})\n",
    "\n",
    "GamingExport.to_csv('GamingExport.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
